[at 0.58 seconds] What will be the most important trends in AI in 
2026? Well, we take a stab at this every year  
[at 6.72 seconds] with with some success, I would say. And this 
time out, I have the knowledgeable assistance  
[at 11.84 seconds] of my colleague, Aaron Baughman, to help us out. 
Well, yeah. You know, after your prediction  
[at 16.56 seconds] of infinite memory last year, I thought maybe 
you could use just a little bit of help. Yeah,  
[at 20.88 seconds] that's that's fair. Well, how about we each take 
four trends each? That sounds good. How about you  
[at 26.24 seconds] first? All right. Okay. So my number one trend 
of 2026 is multi-agent orchestration. Now last  
[at 36.72 seconds] year we said 2025 was the year of the agent. 
AI agents that can reason and plan and take  
[at 42.96 seconds] action on a task and agents I think it's fair 
to say really delivered. There are new numerous  
[at 47.92 seconds] agentic platforms for tasks like coding and basic 
computer use but no single agent really excels at  
[at 55.20 seconds] everything. So, what if you had a whole team of 
agents working together? So, maybe we've got an  
[at 61.28 seconds] agent here that kind of acts as a planner agent 
that decomposes goals into steps. Maybe we have  
[at 68.56 seconds] some worker agents here that do different 
steps like one specializes in writing code,  
[at 75.28 seconds] others call APIs and so forth. And then perhaps 
we have a critic agent that evaluates outputs and  
[at 82.88 seconds] flags issues. And these agents collaborate under 
a coordinating layer that is the orchestrator.  
[at 93.28 seconds] And multi-agent setups like this help introduce 
cross-checking where one agent checks the other  
[at 98.88 seconds] agents work and it can break problems into more 
discrete verifiable steps. Well, great. So,  
[at 105.68 seconds] how could I really follow that trend? 
Well, I think I might just have one. So,  
[at 109.68 seconds] the second one is going to be the digital labor 
workforce. So now these are digital workers that  
[at 116.48 seconds] are autonomous agents that can do a couple 
of items. So the first one is they can parse  
[at 121.52 seconds] a task by interpreting multimodal input. So after 
preparation the worker then executes what's called  
[at 128.08 seconds] a workflow. Now this is where at the end of an 
action plan you know it would follow a sequence of  
[at 135.04 seconds] steps but then it has to be integrated into some 
sort of system that then in turn can take action.  
[at 142.80 seconds] And these could be downstream components. Now 
these systems are then further enhanced by what we  
[at 147.52 seconds] call human-in-the-loop AI, which then provides a 
couple of items. The first one would be oversight.  
[at 153.36 seconds] The next one would be correction and then we're 
looking at these strategic guidance or these rails  
[at 158.72 seconds] um to ensure that all of these agents are doing 
what they're supposed to be doing. Now this  
[at 163.04 seconds] overall trend will create a force multiplying 
effect to extend human capability. Now trend  
[at 169.44 seconds] number three is physical AI. Now we all know that 
large language models they generate text like ABC.  
[at 180.40 seconds] And then there are other models as well. So for 
example there are plenty of diffusion image models  
[at 186.24 seconds] and they generate pixels. They generate images. 
These are all operating in digital space. Now,  
[at 194.40 seconds] physical AI is about models that understand and 
interact with the world that we live in, the the  
[at 201.04 seconds] real 3D world. And this is about models that can 
perceive their environment, reason about physics,  
[at 209.28 seconds] and that can take physical action like robotics. 
So, previously getting a robot like this to do  
[at 217.84 seconds] something useful meant programming explicit rules. 
So if you see an obstacle, you should turn left,  
[at 224.08 seconds] for example. And it was all done by humans. It 
was up to yeah, smart guys like this to code these  
[at 233.68 seconds] rules. Now, physical AI kind of flips that around. 
So you train models in simulation that simulate  
[at 243.04 seconds] the real world and it learns to understand 
how objects behave in the physical world,  
[at 248.48 seconds] how gravity works, how to grasp something without 
crushing it. Now these models are sometimes called  
[at 256.96 seconds] world foundation models. They're generative models 
that can create and understand 3D environments.  
[at 263.28 seconds] They can predict what happens next in a physical 
scene. And in 2026, many of these world models are  
[at 270.56 seconds] taking things like those humanoid robots that you 
found there, Aaron, and they're taking them from  
[at 276.48 seconds] research to commercial production. Physical AI 
is scaling. Well, Martin, you just took my trend,  
[at 283.76 seconds] but let's just go ahead and say number four is 
about social computing. Now, this is a world  
[at 289.60 seconds] where many agents and humans operate within the 
shared AI fabric. So say if I have an agent here  
[at 295.92 seconds] and then a human here. So they're going to be 
connected through this fabric and here if I  
[at 302.56 seconds] have information that flows between the two, they 
begin to understand each other and then they can  
[at 308.32 seconds] gather what the intent is going to be. And then 
once they have the intent and information, they  
[at 313.52 seconds] have actions. They can affect each other or maybe 
even the environment of which they're in. But all  
[at 319.28 seconds] of this flows seamlessly across this system. It's 
this shared space that enables collaboration,  
[at 325.04 seconds] context exchange as well as event effective 
understanding. Now the outcome is really an  
[at 330.32 seconds] empathetic emergent network of these interactions. 
It's what we call this collective intelligence  
[at 335.68 seconds] or this real world swarm computing. So teams of 
agents, digital labor, humanoid robots, and tech  
[at 343.76 seconds] that can understand me with effective computing. 
2026 could be uh quite the year and we're only  
[at 350.16 seconds] halfway through the trends. So trend number five 
that is verifiable AI. Now the EU AI act is coming  
[at 363.12 seconds] and by mid 2026 it becomes fully applicable. 
And think of this a little bit like GDPR but for  
[at 370.96 seconds] artificial intelligence. Now, the core idea here 
is that AI systems, especially high-risk ones,  
[at 377.04 seconds] need to be auditable and they also need to 
be traceable. Now, what does that mean? Well,  
[at 382.56 seconds] it means a few things. It means documentation. 
So, if you're building high-risk AI, you need  
[at 389.12 seconds] technical docs that demonstrate compliance to 
how you tested the models and the risks that you  
[at 394.80 seconds] identified. It means transparency. So, users need 
to know when they're interacting with the machine.  
[at 401.60 seconds] So things like synthetic text, they need to be 
clearly labeled and it means data lineage. You  
[at 408.08 seconds] need to be able to summarize where your training 
data came from and prove you respected copyright  
[at 413.60 seconds] optouts. And just like how GDPR has shaped global 
privacy, not just folks in the EU, the EU AI act  
[at 421.60 seconds] will probably set the template for AI governance 
worldwide. Wow, that's great. And you know, trend  
[at 427.44 seconds] number six, right? It really changes everything, 
but it also changes nothing at the same time.  
[at 433.28 seconds] And now this is where we put in quantum utility 
everywhere. So 2026 is where we start to see this  
[at 440.32 seconds] quantum computing to reliably start solving 
real world problems better, faster, or more  
[at 446.72 seconds] efficiently than classical computing methods. Now, 
at this point, we have this quantum utility scale.  
[at 452.40 seconds] is these systems that begin working alongside and 
together with classical infrastructure to deliver  
[at 457.92 seconds] these practical value in everyday workflows. Now, 
this is going to help with optimization and then  
[at 464.00 seconds] we'll also look at simulation and decision-making. 
Now, all three of these tasks were previously  
[at 470.24 seconds] out of reach within the classical realm. But this 
hybrid quantum classical error, it will begin to  
[at 476.40 seconds] transform quantum computing into this mainstream 
paradigm as it's going to be woven into our  
[at 481.60 seconds] everyday business operations. Now my trend number 
seven is reasoning at the edge. Now last year, we  
[at 490.00 seconds] talked about very small models, models with just 
a few billion parameters that don't need huge  
[at 494.56 seconds] data centers to run. They work on your laptop 
or well maybe even your phone. Well, in 2026,  
[at 501.44 seconds] those small models are learning to think. So, if 
we think about the best models that we have today,  
[at 507.44 seconds] the frontier models, well, pretty much all of them 
now use something called inference time compute.  
[at 516.16 seconds] They spend extra time thinking before giving you 
an answer, working through problems step by step.  
[at 522.64 seconds] Now, the trade-off for that is they need more 
compute. But here's what's changing. Essentially,  
[at 529.92 seconds] teams have figured out how they can distill all 
of this reasoning information into smaller models.  
[at 539.84 seconds] So now these smaller models can perform thinking 
as well. You're taking massive reasoning models  
[at 545.84 seconds] that generate tons of step-by-step solutions and 
we're using that data to train the smaller models  
[at 552.24 seconds] to reason the same way. And that's resulting 
in reasoning models with only a few billion  
[at 557.68 seconds] parameters. They work offline. Your data never 
leaves your device. And there's no roundtrip  
[at 562.56 seconds] latency to a data center. So for anything that's 
real time or mission critical, having a model that  
[at 568.56 seconds] can actually reason through a problem locally is 
a pretty big deal. Yeah. So that's all very true,  
[at 575.52 seconds] Martin. But now our last and final trend is number 
eight. So this is what we're calling amorphous  
[at 582.16 seconds] hybrid computing. So this is a future where both 
AI model topologies and the cloud infrastructure,  
[at 588.24 seconds] they blend into what's called a fluid computing 
backbone. So AI models, they're shifting beyond  
[at 593.68 seconds] just this pure transformer design, right? They're 
beginning to evolve into these other architectures  
[at 599.76 seconds] that integrate transformers and we call them 
these state space models. And then in 2026,  
[at 606.56 seconds] you're also going to see different emerging 
algorithms that are combine both the state space  
[at 611.92 seconds] and transformers and other elements together, 
right? And that's going to be really fun to watch,  
[at 617.76 seconds] very artful. And then at the same time, we have 
this cloud computing piece that's becoming fully  
[at 623.76 seconds] differentiated by combining many different 
chip types. So we're going to have CPUs,  
[at 629.52 seconds] GPUs, TPUs as well. And finally, what we just 
talked about in trend six, quantum, we're going  
[at 637.04 seconds] to have QPUs. I did also want to mention and 
note that you'll see these neuromorphic chips  
[at 642.80 seconds] that are coming out and those emulate the brain. 
But all of these are going to be put together  
[at 648.16 seconds] right into this unified compute environment 
where parts of each of these types of models,  
[at 653.44 seconds] they're going to be automatically mapped to 
the optimal compute substrate. And this is  
[at 657.92 seconds] really going to help to deliver this maximum 
performance and efficiency. And you know what?  
[at 662.80 seconds] Who knows? But at this pace, probably 
not in 2026, but I think further out,  
[at 667.84 seconds] you might see DNA computing entering into the 
mix. Well, those are some lofty goals. And look,  
[at 673.28 seconds] these are what we think are some of the biggest 
AI trends in 2026. But what are we missing?  
[at 681.36 seconds] Which AI trend do you expect to be a big deal in 
2026? Yeah, let us know in the comments below.
